# Tech Challenge 1 - API de Consulta de Livros

Projeto desenvolvido para o Tech Challenge da Fase 1 da PÃ³s-Tech FIAP em Machine Learning Engineering.

## ğŸ“‹ Sobre o Projeto

API REST pÃºblica desenvolvida com FastAPI para gerenciamento e consulta de catÃ¡logo de livros. O projeto inclui funcionalidade completa de web scraping para coleta automÃ¡tica de dados do site [books.toscrape.com](https://books.toscrape.com/), armazenamento em banco de dados SQLite e disponibilizaÃ§Ã£o via endpoints RESTful.

## ğŸ¯ Objetivos do Projeto

- Desenvolver um pipeline completo de extraÃ§Ã£o, transformaÃ§Ã£o e disponibilizaÃ§Ã£o de dados
- Criar uma API pÃºblica escalÃ¡vel e reusÃ¡vel para futuros modelos de Machine Learning
- Implementar web scraping robusto com processamento assÃ­ncrono
- Fornecer endpoints RESTful bem documentados e testados

## ğŸš€ Tecnologias Utilizadas

- **FastAPI** - Framework web moderno e rÃ¡pido para construÃ§Ã£o de APIs
- **SQLAlchemy** - ORM para gerenciamento do banco de dados
- **httpx** - Cliente HTTP assÃ­ncrono para web scraping
- **BeautifulSoup4** - Parser HTML para extraÃ§Ã£o de dados
- **Pydantic** - ValidaÃ§Ã£o de dados e serializaÃ§Ã£o
- **Uvicorn** - Servidor ASGI de alta performance
- **Pytest** - Framework de testes
- **uv** - Gerenciador moderno de dependÃªncias e ambientes virtuais Python

## ğŸ“¦ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.11 ou superior
- [uv](https://github.com/astral-sh/uv) instalado

### Passos de InstalaÃ§Ã£o

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/fiap-7MLET/tech-challenge-1.git
cd tech-challenge-1

# 2. Instale as dependÃªncias usando uv
uv sync

# 3. (Opcional) Ative o ambiente virtual
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

### ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
DATABASE_URL=sqlite:///db.sqlite3
DEBUG=False
```

## ğŸƒ Como Executar

### Iniciar o Servidor de Desenvolvimento

```bash
uv run uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em:
- **API**: http://localhost:8000
- **DocumentaÃ§Ã£o Swagger**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Popular o Banco de Dados

Antes de usar a API, popule o banco de dados com dados dos livros:

```bash
curl -X POST http://localhost:8000/scraping/trigger
```

Este comando irÃ¡:
1. Fazer scraping de aproximadamente 1000 livros do site books.toscrape.com
2. Salvar os dados no banco de dados SQLite
3. Gerar um arquivo CSV em `data/books.csv`
4. Retornar estatÃ­sticas da operaÃ§Ã£o

## ğŸ”§ Endpoints da API

### Endpoints Principais (ObrigatÃ³rios)

#### Health Check
- **GET** `/health/` - Verifica o status da API e conectividade com o banco de dados

#### Livros
- **GET** `/books/` - Lista todos os livros com paginaÃ§Ã£o
  - Query params: `page` (default: 1), `per_page` (default: 10)
  - Resposta inclui URLs de navegaÃ§Ã£o: `next`, `previous`
- **GET** `/books/{id}` - Retorna detalhes de um livro especÃ­fico
- **GET** `/books/search` - Busca livros por tÃ­tulo e/ou categoria
  - Query params: `title`, `category`, `page`, `per_page`
  - Resposta inclui URLs de navegaÃ§Ã£o: `next`, `previous`

#### Categorias
- **GET** `/categories/` - Lista todas as categorias disponÃ­veis com paginaÃ§Ã£o
  - Query params: `page` (default: 1), `per_page` (default: 10)
  - Resposta inclui URLs de navegaÃ§Ã£o: `next`, `previous`

#### Scraping
- **POST** `/scraping/trigger` - Dispara o processo de scraping e popula o banco de dados
- **GET** `/scraping/status` - Retorna estatÃ­sticas do banco de dados (total de livros, categorias, etc.)

### Endpoints Opcionais (BÃ´nus)

#### EstatÃ­sticas (NÃ£o Implementados)
- **GET** `/stats/overview` - EstatÃ­sticas gerais da coleÃ§Ã£o
- **GET** `/stats/categories` - EstatÃ­sticas detalhadas por categoria

#### Livros Extras (NÃ£o Implementados)
- **GET** `/books/top-rated` - Livros com melhor avaliaÃ§Ã£o
- **GET** `/books/price-range` - Filtra livros por faixa de preÃ§o

#### Machine Learning (NÃ£o Implementados)
- **GET** `/ml/features` - Dados formatados para features de ML
- **GET** `/ml/training-data` - Dataset para treinamento
- **POST** `/ml/predictions` - Endpoint para receber prediÃ§Ãµes

#### AutenticaÃ§Ã£o (NÃ£o Implementado)
- **POST** `/auth/register` - Registro de usuÃ¡rio
- **POST** `/auth/login` - Login de usuÃ¡rio
- **POST** `/auth/logout` - Logout de usuÃ¡rio
- **POST** `/auth/refresh` - RenovaÃ§Ã£o de token

## ğŸŒ Exemplos de Uso

A API pode ser testada de duas formas: via **linha de comando (curl)** ou via **Swagger UI (interface grÃ¡fica)**. Recomendamos usar o Swagger UI para exploraÃ§Ã£o inicial, pois oferece documentaÃ§Ã£o interativa e validaÃ§Ã£o automÃ¡tica.

### ğŸ“– Acessando a DocumentaÃ§Ã£o Interativa

**Swagger UI**: http://localhost:8000/docs
**ReDoc**: http://localhost:8000/redoc

---

### Verificar Status da API

**Via curl:**
```bash
curl http://localhost:8000/health/
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /health/`
3. Clique em "Try it out" â†’ "Execute"
4. Visualize a resposta com status da API e conectividade do banco

---

### Listar Livros (com paginaÃ§Ã£o)

**Via curl:**
```bash
curl "http://localhost:8000/books/?page=1&per_page=10"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /books/`
3. Clique em "Try it out"
4. Ajuste os parÃ¢metros:
   - `page`: 1
   - `per_page`: 10
5. Clique em "Execute"

**Resposta de exemplo:**
```json
{
  "data": [
    {
      "id": 1,
      "title": "A Light in the Attic",
      "price": "51.77",
      "rating": 3,
      "availability": true,
      "category": "Poetry",
      "image": "https://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg"
    }
  ],
  "page": 1,
  "per_page": 10,
  "total": 100,
  "pages": 10,
  "next": "http://localhost:8000/books/?page=2&per_page=10",
  "previous": null
}
```

---

### Buscar Livro por ID

**Via curl:**
```bash
curl "http://localhost:8000/books/1"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /books/{id}`
3. Clique em "Try it out"
4. Insira o `id` desejado (ex: 1)
5. Clique em "Execute"

**Resposta de exemplo:**
```json
{
  "id": 1,
  "title": "A Light in the Attic",
  "price": "51.77",
  "rating": 3,
  "availability": true,
  "category": "Poetry",
  "image": "https://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg"
}
```

---

### Buscar Livros por TÃ­tulo

**Via curl:**
```bash
curl "http://localhost:8000/books/search?title=python&page=1&per_page=10"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /books/search`
3. Clique em "Try it out"
4. Preencha os parÃ¢metros:
   - `title`: "python"
   - `page`: 1
   - `per_page`: 10
5. Clique em "Execute"

**Resposta de exemplo:**
```json
{
  "data": [
    {
      "id": 23,
      "title": "Learning Python",
      "price": "30.23",
      "rating": 4,
      "availability": true,
      "category": "Programming",
      "image": "https://books.toscrape.com/media/cache/..."
    }
  ],
  "page": 1,
  "per_page": 10,
  "total": 15,
  "pages": 2,
  "next": "http://localhost:8000/books/search?title=python&per_page=10&page=2",
  "previous": null
}
```

---

### Buscar Livros por Categoria

**Via curl:**
```bash
curl "http://localhost:8000/books/search?category=Fiction&page=1&per_page=10"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /books/search`
3. Clique em "Try it out"
4. Preencha:
   - `category`: "Fiction"
   - `page`: 1
   - `per_page`: 10
5. Clique em "Execute"

---

### Listar Todas as Categorias

**Via curl:**
```bash
curl "http://localhost:8000/categories/?page=1&per_page=20"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /categories/`
3. Clique em "Try it out"
4. Ajuste:
   - `page`: 1
   - `per_page`: 20
5. Clique em "Execute"

**Resposta de exemplo:**
```json
{
  "data": [
    {"name": "Travel", "count": 11},
    {"name": "Mystery", "count": 32},
    {"name": "Historical Fiction", "count": 14}
  ],
  "page": 1,
  "per_page": 20,
  "total": 50,
  "pages": 3,
  "next": "http://localhost:8000/categories/?page=2&per_page=20",
  "previous": null
}
```

---

### Disparar Processo de Scraping

**Via curl:**
```bash
curl -X POST http://localhost:8000/scraping/trigger
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `POST /scraping/trigger`
3. Clique em "Try it out"
4. Clique em "Execute"
5. Aguarde o processo concluir (pode levar alguns minutos)

**Resposta de exemplo:**
```json
{
  "status": "completed",
  "total_books": 1000,
  "total_categories": 50,
  "csv_file": "data/books.csv",
  "execution_time": "45.2s"
}
```

---

### Verificar Status do Scraping

**Via curl:**
```bash
curl "http://localhost:8000/scraping/status"
```

**Via Swagger:**
1. Acesse http://localhost:8000/docs
2. Localize `GET /scraping/status`
3. Clique em "Try it out" â†’ "Execute"

**Resposta de exemplo:**
```json
{
  "total_books": 1000,
  "total_categories": 50,
  "last_updated": "2025-10-21T14:30:00"
}
```

---

### ğŸ’¡ Dicas para Usar o Swagger UI

- **Schemas**: Role atÃ© o final da pÃ¡gina do Swagger para ver todos os modelos de dados
- **ValidaÃ§Ã£o**: O Swagger valida automaticamente os tipos de dados antes de enviar
- **Exemplos**: Clique em "Schema" ao lado de "Example Value" para ver a estrutura completa
- **Download**: Baixe a especificaÃ§Ã£o OpenAPI em http://localhost:8000/openapi.json
- **AutorizaÃ§Ã£o**: Quando implementada autenticaÃ§Ã£o, use o botÃ£o "Authorize" no topo

## ğŸ“ Estrutura do Projeto

```
tech-challenge-1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ schemas/          # Schemas Pydantic para validaÃ§Ã£o
â”‚   â”‚       â””â”€â”€ book.py
â”‚   â”œâ”€â”€ models/                # Modelos SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ book.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ routes/                # Rotas da API (endpoints)
â”‚   â”‚   â”œâ”€â”€ book_routes.py
â”‚   â”‚   â”œâ”€â”€ category_routes.py
â”‚   â”‚   â”œâ”€â”€ health_routes.py
â”‚   â”‚   â”œâ”€â”€ scraping_routes.py
â”‚   â”‚   â”œâ”€â”€ stats_routes.py
â”‚   â”‚   â”œâ”€â”€ ml_routes.py
â”‚   â”‚   â””â”€â”€ user_routes.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ scraping/         # LÃ³gica de web scraping
â”‚   â”‚       â”œâ”€â”€ core.py       # Scraper assÃ­ncrono principal
â”‚   â”‚       â””â”€â”€ file_handler.py  # ManipulaÃ§Ã£o de arquivos CSV
â”‚   â”œâ”€â”€ extensions.py          # ConfiguraÃ§Ã£o do banco de dados
â”‚   â”œâ”€â”€ conf.py                # ConfiguraÃ§Ãµes gerais
â”‚   â””â”€â”€ app.py                 # AplicaÃ§Ã£o principal FastAPI
â”œâ”€â”€ data/                      # Dados gerados (CSV)
â”œâ”€â”€ migrations/                # Migrations do banco de dados
â”œâ”€â”€ tests/                     # Testes automatizados
â”œâ”€â”€ pyproject.toml            # ConfiguraÃ§Ã£o de dependÃªncias (uv/pip)
â”œâ”€â”€ uv.lock                   # Lock file do uv
â”œâ”€â”€ Tech_Challenge_API.postman_collection.json  # ColeÃ§Ã£o Postman
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸ—„ï¸ Banco de Dados

### Modelo de Dados

O projeto utiliza SQLite como banco de dados com a seguinte estrutura:

**Tabela: books**
- `id` (Integer, PK) - Identificador Ãºnico
- `title` (String) - TÃ­tulo do livro (Ãºnico)
- `price` (Numeric) - PreÃ§o do livro
- `rating` (Integer) - AvaliaÃ§Ã£o de 1 a 5
- `availability` (Boolean) - Disponibilidade em estoque
- `category` (String) - Categoria do livro
- `image` (String) - URL da imagem

### Gerenciamento do Banco

O banco de dados Ã© criado automaticamente na primeira execuÃ§Ã£o em `db.sqlite3`.

## ğŸ•·ï¸ Web Scraping

### CaracterÃ­sticas do Scraper

- **AssÃ­ncrono**: Utiliza `httpx` e `asyncio` para mÃ¡xima performance
- **Robusto**: Tratamento de erros e retry automÃ¡tico
- **Completo**: Extrai todos os campos necessÃ¡rios (tÃ­tulo, preÃ§o, rating, categoria, imagem)
- **EscalÃ¡vel**: Processa mÃºltiplas pÃ¡ginas em paralelo
- **Logging**: Registra progresso e erros durante a execuÃ§Ã£o

### Fonte de Dados

- **URL**: https://books.toscrape.com/
- **Campos ExtraÃ­dos**:
  - TÃ­tulo do livro
  - PreÃ§o (em libras)
  - Rating (1-5 estrelas)
  - Disponibilidade em estoque
  - Categoria
  - URL da imagem

## ğŸ§ª Testes

### Executar Testes

```bash
# Executar todos os testes
uv run pytest

# Executar com output detalhado
uv run pytest -v

# Executar com cobertura de cÃ³digo
uv run pytest --cov=src --cov-report=html
```

### Cobertura de Testes

O projeto inclui testes para:
- âœ… Rotas da API
- âœ… Modelos de dados
- âœ… Schemas Pydantic
- âœ… FunÃ§Ãµes de scraping
- âœ… ManipulaÃ§Ã£o de arquivos CSV

## ğŸ“Š ColeÃ§Ã£o Postman

Uma coleÃ§Ã£o Postman completa estÃ¡ disponÃ­vel em `Tech_Challenge_API.postman_collection.json` com todos os endpoints configurados e exemplos de requisiÃ§Ãµes.

### Importar no Postman

1. Abra o Postman
2. Clique em "Import"
3. Selecione o arquivo `Tech_Challenge_API.postman_collection.json`
4. A coleÃ§Ã£o estarÃ¡ disponÃ­vel com todos os endpoints prÃ©-configurados

## ğŸ—ï¸ Arquitetura e Pipeline de Dados

### Fluxo de Dados

```
[books.toscrape.com]
    â†“ (Web Scraping - httpx + BeautifulSoup)
[Dados Brutos]
    â†“ (TransformaÃ§Ã£o e Limpeza)
[Dados Estruturados]
    â†“ (Armazenamento Dual)
    â”œâ†’ [SQLite Database] â†’ [FastAPI] â†’ [Endpoints REST] â†’ [Consumidores]
    â””â†’ [CSV File] â†’ [AnÃ¡lise/ML]
```

### Escalabilidade Futura

A arquitetura foi desenhada pensando em:
- **Modularidade**: Componentes independentes e reutilizÃ¡veis
- **Extensibilidade**: FÃ¡cil adiÃ§Ã£o de novos endpoints e funcionalidades
- **ML-Ready**: Estrutura preparada para integraÃ§Ã£o com modelos de ML
- **Cache**: Possibilidade de adicionar camada de cache (Redis)
- **Queue**: Preparado para adicionar filas de processamento (Celery)

## ğŸ“ CenÃ¡rio de Uso para ML

Esta API foi desenvolvida pensando em servir como base para:
1. **Sistemas de RecomendaÃ§Ã£o**: Dados estruturados de livros, categorias e ratings
2. **AnÃ¡lise de PreÃ§os**: HistÃ³rico e comparaÃ§Ã£o de preÃ§os
3. **ClassificaÃ§Ã£o de Texto**: CategorizaÃ§Ã£o automÃ¡tica baseada em tÃ­tulos
4. **Feature Engineering**: Endpoints preparados para exportar features

## ğŸ‘¥ Equipe

Desenvolvido como parte do Tech Challenge - Fase 1
PÃ³s-Tech FIAP - Machine Learning Engineering

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

**ObservaÃ§Ã£o**: Este projeto foi desenvolvido para fins educacionais como parte do Tech Challenge da FIAP.
